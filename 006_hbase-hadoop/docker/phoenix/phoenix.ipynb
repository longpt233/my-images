{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "040a5dd5-b76c-4b66-af39-c3622809b51f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/12/20 18:07:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# một task spark sẽ đi kèm với 1 pipeline, tức là có 10job thì sẽ có 20task spark và 10 pipeline\n",
    "# Tạo SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .appName(\"WriteToPhoenixHello\") \\\n",
    "    .config(\"spark.jars\", \"/tmp/phoenix5-spark3-6.0.0.7.2.17.0-334.jar,/tmp/phoenix-hbase-compat-2.4.1-5.1.3.jar,\\\n",
    "    /usr/local/phoenix/phoenix-client-hbase-2.4-5.1.3.jar,/tmp/phoenix-core-5.1.3.jar,/tmp/acryl-spark-lineage-5206f9d-SNAPSHOT.jar\") \\\n",
    "        .config(\"spark.extraListeners\", \"datahub.spark.DatahubSparkListener\")\\\n",
    "        .config(\"spark.datahub.rest.server\", \"http://10.208.164.167:8080\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "# Tạo DataFrame mẫu\n",
    "data = [\n",
    "    (1, \"John Doe\", 25),\n",
    "    (2, \"Jane Smith\", 30),\n",
    "    (3, \"Alice Johnson\", 22)\n",
    "]\n",
    "columns = [\"id\", \"name\", \"age\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "\n",
    "# df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12279f41-e0d4-4f87-a315-eb79938590db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/12/20 18:07:55 WARN CompositeMeterRegistry: A MeterFilter is being configured after a Meter has been registered to this registry. All MeterFilters should be configured before any Meters are registered. If that is not possible or you have a use case where it should be allowed, let the Micrometer maintainers know at https://github.com/micrometer-metrics/micrometer/issues/4920. Enable DEBUG level logging on this logger to see a stack trace of the call configuring this MeterFilter.\n",
      "24/12/20 18:07:55 WARN OpenLineageToDataHub: alo alaoala {\"eventTime\":\"2024-12-20T11:07:54.702Z\",\"producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"schemaURL\":\"https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunEvent\",\"eventType\":\"START\",\"run\":{\"runId\":\"0193e3c0-ab93-7314-89c4-5758d3ee66e5\",\"facets\":{\"parent\":{\"_producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"_schemaURL\":\"https://openlineage.io/spec/facets/1-0-1/ParentRunFacet.json#/$defs/ParentRunFacet\",\"run\":{\"runId\":\"0193e3c0-ab91-76a5-b58c-5d66680bf827\"},\"job\":{\"namespace\":\"default\",\"name\":\"write_to_phoenix_hello\"}},\"processing_engine\":{\"_producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"_schemaURL\":\"https://openlineage.io/spec/facets/1-1-1/ProcessingEngineRunFacet.json#/$defs/ProcessingEngineRunFacet\",\"version\":\"3.3.1\",\"name\":\"spark\"},\"environment-properties\":{\"_producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"_schemaURL\":\"https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunFacet\",\"environment-properties\":{}},\"spark_jobDetails\":{\"_producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"_schemaURL\":\"https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunFacet\",\"jobId\":0},\"spark_properties\":{\"_producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"_schemaURL\":\"https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunFacet\",\"properties\":{\"spark.master\":\"local[1]\",\"spark.app.name\":\"WriteToPhoenixHello\"}}}},\"job\":{\"namespace\":\"default\",\"name\":\"write_to_phoenix_hello.execute_save_into_data_source_command.my_table\",\"facets\":{\"jobType\":{\"_producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"_schemaURL\":\"https://openlineage.io/spec/facets/2-0-2/JobTypeJobFacet.json#/$defs/JobTypeJobFacet\",\"processingType\":\"BATCH\",\"integration\":\"SPARK\",\"jobType\":\"SQL_JOB\"}}},\"inputs\":[],\"outputs\":[]}\n",
      "24/12/20 18:07:55 WARN OpenLineageToDataHub: table name11 my_table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/12/20 18:07:55 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-phoenix.properties,hadoop-metrics2.properties\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/12/20 18:07:56 WARN OpenLineageToDataHub: alo alaoala {\"eventTime\":\"2024-12-20T11:07:56.765Z\",\"producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"schemaURL\":\"https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunEvent\",\"eventType\":\"COMPLETE\",\"run\":{\"runId\":\"0193e3c0-ab93-7314-89c4-5758d3ee66e5\",\"facets\":{\"parent\":{\"_producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"_schemaURL\":\"https://openlineage.io/spec/facets/1-0-1/ParentRunFacet.json#/$defs/ParentRunFacet\",\"run\":{\"runId\":\"0193e3c0-ab91-76a5-b58c-5d66680bf827\"},\"job\":{\"namespace\":\"default\",\"name\":\"write_to_phoenix_hello\"}},\"processing_engine\":{\"_producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"_schemaURL\":\"https://openlineage.io/spec/facets/1-1-1/ProcessingEngineRunFacet.json#/$defs/ProcessingEngineRunFacet\",\"version\":\"3.3.1\",\"name\":\"spark\"},\"environment-properties\":{\"_producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"_schemaURL\":\"https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunFacet\",\"environment-properties\":{}},\"spark_properties\":{\"_producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"_schemaURL\":\"https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunFacet\",\"properties\":{\"spark.master\":\"local[1]\",\"spark.app.name\":\"WriteToPhoenixHello\"}}}},\"job\":{\"namespace\":\"default\",\"name\":\"write_to_phoenix_hello.execute_save_into_data_source_command.my_table\",\"facets\":{\"jobType\":{\"_producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"_schemaURL\":\"https://openlineage.io/spec/facets/2-0-2/JobTypeJobFacet.json#/$defs/JobTypeJobFacet\",\"processingType\":\"BATCH\",\"integration\":\"SPARK\",\"jobType\":\"SQL_JOB\"}}},\"inputs\":[],\"outputs\":[]}\n",
      "24/12/20 18:07:56 WARN OpenLineageToDataHub: table name11 my_table\n",
      "Data written to Phoenix successfully!\n",
      "24/12/20 18:07:56 WARN OpenLineageToDataHub: alo alaoala {\"eventTime\":\"2024-12-20T11:07:56.832Z\",\"producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"schemaURL\":\"https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunEvent\",\"eventType\":\"COMPLETE\",\"run\":{\"runId\":\"0193e3c0-ab93-7314-89c4-5758d3ee66e5\",\"facets\":{\"parent\":{\"_producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"_schemaURL\":\"https://openlineage.io/spec/facets/1-0-1/ParentRunFacet.json#/$defs/ParentRunFacet\",\"run\":{\"runId\":\"0193e3c0-ab91-76a5-b58c-5d66680bf827\"},\"job\":{\"namespace\":\"default\",\"name\":\"write_to_phoenix_hello\"}},\"processing_engine\":{\"_producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"_schemaURL\":\"https://openlineage.io/spec/facets/1-1-1/ProcessingEngineRunFacet.json#/$defs/ProcessingEngineRunFacet\",\"version\":\"3.3.1\",\"name\":\"spark\"},\"environment-properties\":{\"_producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"_schemaURL\":\"https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunFacet\",\"environment-properties\":{}},\"spark_properties\":{\"_producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"_schemaURL\":\"https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunFacet\",\"properties\":{\"spark.master\":\"local[1]\",\"spark.app.name\":\"WriteToPhoenixHello\"}}}},\"job\":{\"namespace\":\"default\",\"name\":\"write_to_phoenix_hello.execute_save_into_data_source_command.my_table\",\"facets\":{\"jobType\":{\"_producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"_schemaURL\":\"https://openlineage.io/spec/facets/2-0-2/JobTypeJobFacet.json#/$defs/JobTypeJobFacet\",\"processingType\":\"BATCH\",\"integration\":\"SPARK\",\"jobType\":\"SQL_JOB\"}}},\"inputs\":[],\"outputs\":[]}\n",
      "24/12/20 18:07:56 WARN OpenLineageToDataHub: table name11 my_table\n",
      "24/12/20 18:07:56 WARN OpenLineageToDataHub: alo alaoala {\"eventTime\":\"2024-12-20T11:07:56.833Z\",\"producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"schemaURL\":\"https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunEvent\",\"eventType\":\"COMPLETE\",\"run\":{\"runId\":\"0193e3c0-ab91-76a5-b58c-5d66680bf827\",\"facets\":{\"processing_engine\":{\"_producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"_schemaURL\":\"https://openlineage.io/spec/facets/1-1-1/ProcessingEngineRunFacet.json#/$defs/ProcessingEngineRunFacet\",\"version\":\"3.3.1\",\"name\":\"spark\"},\"environment-properties\":{\"_producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"_schemaURL\":\"https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunFacet\",\"environment-properties\":{}},\"spark_properties\":{\"_producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"_schemaURL\":\"https://openlineage.io/spec/2-0-2/OpenLineage.json#/$defs/RunFacet\",\"properties\":{\"spark.master\":\"local[1]\",\"spark.app.name\":\"WriteToPhoenixHello\"}}}},\"job\":{\"namespace\":\"default\",\"name\":\"write_to_phoenix_hello\",\"facets\":{\"jobType\":{\"_producer\":\"https://github.com/OpenLineage/OpenLineage/tree/1.16.0/integration/spark\",\"_schemaURL\":\"https://openlineage.io/spec/facets/2-0-2/JobTypeJobFacet.json#/$defs/JobTypeJobFacet\",\"processingType\":\"NONE\",\"integration\":\"SPARK\",\"jobType\":\"APPLICATION\"}}},\"inputs\":[],\"outputs\":[]}\n"
     ]
    }
   ],
   "source": [
    "# Cấu hình kết nối Phoenix\n",
    "phoenix_url = \"jdbc:phoenix:localhost\"  # Thay đổi 'localhost' thành địa chỉ ZooKeeper của bạn\n",
    "table_name = \"my_table\"\n",
    "\n",
    "\n",
    "# 0: jdbc:phoenix:localhost> CREATE TABLE IF NOT EXISTS my_table (\n",
    "# . . . . . . . . . . . . )>     id INTEGER NOT NULL,\n",
    "# . . . . . . . . . . . . )>     name VARCHAR,\n",
    "# . . . . . . . . . . . . )>     age INTEGER,\n",
    "# . . . . . . . . . . . . )>     CONSTRAINT pk PRIMARY KEY (id)\n",
    "# . . . . . . . . . . . . )> );\n",
    "\n",
    "# Ghi DataFrame vào Phoenix\n",
    "df.write \\\n",
    "    .format(\"org.apache.phoenix.spark\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"zkUrl\", phoenix_url) \\\n",
    "    .option(\"table\", table_name) \\\n",
    "    .save()\n",
    "\n",
    "print(\"Data written to Phoenix successfully!\")\n",
    "\n",
    "# Dừng SparkSession\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
