<configuration>
    <property>
        <name>metastore.thrift.uris</name>
        <value>thrift://0.0.0.0:9083</value>
        <description>Thrift URI for the remote metastore. Used by metastore client to connect to remote metastore.</description>
    </property>
    <property>
        <name>metastore.task.threads.always</name>
        <value>org.apache.hadoop.hive.metastore.events.EventCleanerTask,org.apache.hadoop.hive.metastore.MaterializationsCacheCleanerTask</value>
    </property>
    <property>
        <name>metastore.expression.proxy</name>
        <value>org.apache.hadoop.hive.metastore.DefaultPartitionExpressionProxy</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>org.postgresql.Driver</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:postgresql://10.208.164.167:5431/hive_db</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>admin</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>admin</value>
    </property>
    <!-- <property>
        <name>metastore.try.direct.sql.ddl</name>
        <value>false</value>
    </property> -->


    <property>
        <name>hive.metastore.warehouse.dir</name>
        <value>s3a://hive/warehouse</value>
    </property>

    <property>
        <name>fs.s3a.impl</name>
        <value>org.apache.hadoop.fs.s3a.S3AFileSystem</value>
    </property>

    <!-- <property>
        <name>fs.s3a.connection.ssl.enabled</name>
        <value>true</value>
    </property> -->

    <property>
        <name>metastore.task.threads.always</name>
        <value>org.apache.hadoop.hive.metastore.events.EventCleanerTask</value>
        <description>bản hms 3.1.2 bị lỗi  MaterializationsCacheCleanerTask class not found không lên được chắc là cần config này. https://stackoverflow.com/questions/75905954/hive-meta-store-in-docker</description>
    </property>

    <property>
        <name>fs.s3a.access.key</name>
        <value>minio</value>
    </property>
    <property>
        <name>fs.s3a.secret.key</name>
        <value>minio123</value>
    </property>
    <property>
        <name>fs.s3a.endpoint</name>
        <value>http://10.208.164.167:9000</value>
    </property>
    <property>
        <name>fs.s3a.path.style.access</name>
        <value>true</value>
    </property>

    <!-- TODO HIVE_METASTORE_WAREHOUSE_DIR: s3://datalake/  -->

    <!-- Enable ACID support -->
    <property>
    <name>hive.support.concurrency</name>
    <value>true</value>
    </property>
    <property>
    <name>hive.enforce.bucketing</name>
    <value>true</value>
    </property>
    <property>
    <name>hive.exec.dynamic.partition.mode</name>
    <value>nostrict</value>
    </property>
    <property>
    <name>hive.txn.manager</name>
    <value>org.apache.hadoop.hive.ql.lockmgr.DbTxnManager</value>
    </property>
    <property>
    <name>hive.compactor.initiator.on</name>
    <value>true</value>
    </property>
    <property>
    <name>hive.compactor.worker.threads</name>
    <value>1</value>
    </property>

    <!-- <property>
        <name>hive.txn.manager.log.dir</name>
        <value>/etc/trino</value>
    </property> -->

</configuration>